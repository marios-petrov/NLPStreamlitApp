# BERTSummarizer VS WikipediaAPI
|| Final Project for Intermediate Python ||

In this project, I aim to employ a pre-trained BERT summarizer model to extract and produce summaries for any wikipedia page or raw text input. My goal is to pin BERT vs the "stock" wikipedia API summarizer and evaljuate the performance of each.

This project's application framework will be constructed and hosted by Streamlit


# How To Use Application
To effectively use this StreamLit application, simply open the provided link:
[SampleLink]
Afterward, navigate to the large blank search bar, and either paste a wikipedia link or input some raw text.
Then, select the size of your desired summary [short], [average], or [long]
After a short period of time:
-If [input] is raw text you will recieve a BERT generated summary of said text
-If [input] is in the form of a wikipedia link you will recieve two text summaries, one generated by BERT and one generated by the automated wikipediaAPI
Enjoy your summarization!

# Performance Analysis and Evaluation
seperate from the actual application, if you want to evaluate the performance of the BERT based summarizer when compared to the wikipediaAPI, simply run the AlgorithEvaluation module and input an appropriate wikipedia text article. The ROGUE-Evaluation scores for both summaries will be presented.






